<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Shubao Liu Homepage</title>
    <description>an AI Researcher and Builder. Interested in machine learning, computer vision and natural language processing. Focusing on unsupervised learning.
</description>
    <link>http://shubaoliu.github.com/</link>
    <atom:link href="http://shubaoliu.github.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 21 Dec 2016 19:04:38 -0500</pubDate>
    <lastBuildDate>Wed, 21 Dec 2016 19:04:38 -0500</lastBuildDate>
    <generator>Jekyll v3.1.3</generator>
    
      <item>
        <title>Difficulty Levels of Different AI Tasks</title>
        <description>&lt;p&gt;Can we measure the difficulty levels of different AI tasks? For example, is playing Go game more difficult than doing chores? This problem arose on the public media earlier this year, due to the media coverage of historic moment of AlphaGo defending Lee Sedol. There is a related question: Can we gauge the progress of artificial intelligence compared with human intelligence?&lt;/p&gt;

&lt;p&gt;Based on the AI development history, our answer is likely to be “NOT SO MUCH”. The history shows that what we thought more difficult AI tasks are less difficult than the ones we thought easier, and vice versa.&lt;/p&gt;

&lt;p&gt;AI has a surprising history, with several ups and downs, in the past half of century. This is partly correlated with our assessment of the difficult levels of different AI tasks. Initially, we thought board games (such as chess and go) was harder, while perception processing (such as listening, seeing) was easier. This idea is formed by extrapolating from our own experience of biological intelligence, where computation and logic is harder than perception, which seems effortless. Now the history has proven that we were completely wrong. So our assessment of the difficult level of different AI tasks have changed dramatically over the past few decades.&lt;/p&gt;

&lt;p&gt;Generally speaking, we take two approaches in measuring the AI task difficulties. The first approach is purely empirical and retrospective: We generally assume that all the AI tasks we have solved are easier, while the ones we haven’t solved yet are more difficult. So now, we think doing chores is more difficult than playing board games, including Go.&lt;/p&gt;

&lt;p&gt;The second approach argues that some tasks are inherently more difficult because they needs to achieve the same goals based on less information. For example, we can say that unsupervised learning is more difficult than supervised learning, because it does not require additional task-specific annotations. The problem with this approach is that there are many tasks that are parallel (in the sense that they process different kinds of inforamtion), and we cannot measure their relative degree of difficulty based on that. For example, you cannot say that understanding language (NLP) is more difficult than understanding the visual world (computer vision), and vice versa.&lt;/p&gt;

</description>
        <pubDate>Wed, 21 Dec 2016 00:00:00 -0500</pubDate>
        <link>http://shubaoliu.github.com/blog/2016/12/21/difficulty-levels-of-different-ai-tasks.html</link>
        <guid isPermaLink="true">http://shubaoliu.github.com/blog/2016/12/21/difficulty-levels-of-different-ai-tasks.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Three Aspects of Brain-Like Learning</title>
        <description>&lt;p&gt;Artificial intelligence (AI) has become a hot topic (again), due to the recent success (and hype) of deep learning.&lt;/p&gt;

&lt;p&gt;The technological breakthrough of deep learning is real and has made many things from impossible to possible. The excitement has made some people believe we will soon achieve human brain-level intelligence, or so called “singularity”.&lt;/p&gt;

&lt;p&gt;We need to be cautious on what we have achieved. In this figure below, I list three aspects of brain-level learning capability:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;learning from labeled raw data,&lt;/li&gt;
  &lt;li&gt;learning from unlabeled data, and&lt;/li&gt;
  &lt;li&gt;learning from little data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These three aspects are illustrated as the three dimensions of a cube, where the brain-like intelligence lies at the far-right corner. We need all of these three capabilities to achieve human brain-level AI.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/images/three_dimensions_of_brain_like_learning.png&quot; width=&quot;350&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;What we have achieved with deep learning is only the first dimension: learning from labeled raw data. Given large amount of input-output pair training data, it automatically learns hierarchical features and build an input-to-output mapping. This kind of learning is also called imitation learning. It has severe limitations: It never learns anything new other than imitating what’s provided; It has poor adaptivity with the changing environment; And it requires large amount of expert provided training data. This is an expensive solution in many applications, such as health care. This is also a fragile solution in many fully autonomous applications, such as self-driving cars and robotics, where the AI agent needs to adapt to constantly changing environment. And this does not provide a solution for applications where we need to discover new patterns in data.&lt;/p&gt;

&lt;p&gt;What we need next is breakthroughs in unsupervised learning and semi-supervised learning, which will create machines that can learn autonomously from the unlabeled raw data with little or no supervision. This is the next frontier of AI research.&lt;/p&gt;

&lt;p&gt;In summary, we need to make progress in the following three paradigms at the same time to achieve the three capabilities of brain-like learning:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;deep (supervised) learning,&lt;/li&gt;
  &lt;li&gt;unsupervised learning,&lt;/li&gt;
  &lt;li&gt;semi-supervised learning.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Fri, 09 Dec 2016 00:00:00 -0500</pubDate>
        <link>http://shubaoliu.github.com/blog/2016/12/09/three-aspects-of-brain-like-learning.html</link>
        <guid isPermaLink="true">http://shubaoliu.github.com/blog/2016/12/09/three-aspects-of-brain-like-learning.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Welcome!</title>
        <description>&lt;p&gt;In this new website, I want to blog about my work and some fun stuff. The work topics will include unsupervised learning, deep learning, computer vision, etc. I hope you will enjoy it.&lt;/p&gt;

&lt;p&gt;You can subscribe &lt;a href=&quot;/feed.xml&quot;&gt;via RSS&lt;/a&gt; to receive lastest updates.&lt;/p&gt;

&lt;p&gt;This site is built with &lt;a href=&quot;http://jekyllrb.com&quot;&gt;Jekyll&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Fri, 29 Apr 2016 00:00:00 -0400</pubDate>
        <link>http://shubaoliu.github.com/blog/2016/04/29/welcome.html</link>
        <guid isPermaLink="true">http://shubaoliu.github.com/blog/2016/04/29/welcome.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
